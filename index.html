<!doctype html>
<html>

<head>
    <meta charset="utf-8">

    <title>Hi there! I'm å‘¨å²±ğŸ‘‹</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


    <!-- set page stylesheet -->
    <link rel="stylesheet" href="/css/shared.css" type="text/css">
    <link rel="stylesheet" href="/css/navbar.css" type="text/css">

</head>

<body>

    <div class="container_bg navbar">
        <img src="/img/è¥¿ç”µlogo.jpg" alt="XDU Logo" class="navbar-logo">
        <h2>
            <a href="/index.html">HOME</a>&nbsp;&nbsp;<span class="delimiter">&middot;</span>&nbsp;&nbsp;
            <a href="/project.html">PROJECT</a>&nbsp;&nbsp;<span
                class="delimiter">&middot;</span>&nbsp;
            <a href="/record.html">RECORD</a>
            <!-- <a href="/open_source.html">Open Source</a>&nbsp;&nbsp;&middot;&nbsp; -->
            <!-- <a href="/awards.html">Awards</a> -->
        </h2>
    </div>

    <div class="container">
        <div id="group" align="center">
            <h1>Hi there! ğŸ‘‹ Welcome to my homepage!</h1>
        </div>
        <div id="sidebar">
            <img src="/img/avatar.jpg" vspace="30 px" width="250 px" id="me" itemprop="photo"></img>
        </div>

        <div id="bio">

            <br>

            <h1>
                <span itemprop="name">Dai ZhouğŸŠ <font size="6">å‘¨å²±</font> </span>
            </h1>

            <p style="line-height:23px;">
                Undergraduate
                <br>
                <br>
                Robotics Engineering Major
                <br>
                Xidian University
                <br>
                Xi'an, China 710071
                <br>
                <br>
                <br>
                Email: 2633127336@qq.com

                <br>
            </p>
        </div>
    </div>

    <div class="container">
        <h2>ğŸŠResearch Directions</h2>
        <p>ğŸ¤– å…·èº«æ™ºèƒ½æ“ä½œ / Embodied Manipulation</p>
        <p>ğŸ¦¾ çµå·§æ‰‹ / Dexterous Hands</p>
        <p>ğŸ¯ æœºå™¨äººå¼ºåŒ–å­¦ä¹  / Robot Reinforcement Learning</p>
        <p>ğŸ§© å˜å½¢æœºå™¨äºº / Morphing Robots</p>
    </div>

    <div class="container">
        <h2>ğŸŠShort Bio</h2>
        <p class="chinese">
            æˆ‘ç›®å‰å°±è¯»äºè¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦æœºç”µå·¥ç¨‹å­¦é™¢æœºå™¨äººå·¥ç¨‹ä¸“ä¸šï¼ˆ2023.9-2027.7ï¼‰ï¼Œ
            æœ¬ç§‘åœ¨è¯»æœŸé—´å­¦ä¸šæˆç»©ä¼˜å¼‚ï¼Œä¸“ä¸šæ’åç¨³å±…å‰åˆ—ï¼ˆ1/45ï¼‰ã€‚æ ¸å¿ƒè¯¾ç¨‹è¡¨ç°çªå‡ºï¼Œ
            å…¶ä¸­å›¾å­¦åŸºç¡€ä¸è®¡ç®—æœºç»˜å›¾ï¼ˆ100ï¼‰ã€æœºå™¨äººé©±åŠ¨æŠ€æœ¯ï¼ˆ99ï¼‰ã€è®¡ç®—æœºå¯¼è®ºä¸ç¨‹åºè®¾è®¡ï¼ˆ97ï¼‰ã€
            æœºå™¨äººæŠ€æœ¯&è‡ªåŠ¨æ§åˆ¶åŸç†ï¼ˆ96ï¼‰ã€é«˜ç­‰æ•°å­¦&æ¨¡æ‹Ÿç”µå­æŠ€æœ¯åŸºç¡€&å·¥ç¨‹åŠ›å­¦ï¼ˆ95ï¼‰ã€‚
            å¤–è¯­èƒ½åŠ›æ–¹é¢ï¼Œå·²é€šè¿‡å¤§å­¦è‹±è¯­å…­çº§ï¼ˆCET-6ï¼‰ï¼Œå…·å¤‡è‰¯å¥½çš„è‹±æ–‡æ–‡çŒ®é˜…è¯»ä¸å­¦æœ¯äº¤æµåŸºç¡€ã€‚
        </p>
        <p class="chinese">
            <strong>æˆæœï¼š</strong><br>
            å›½å®¶çº§å¤§å­¦ç”Ÿåˆ›ä¸šåˆ›æ–°é¡¹ç›®â€œç´¢ç‰µå¼•ä»¿ç”Ÿæ‰‹â€æ‹…ä»»é¡¹ç›®è´Ÿè´£äººï¼›<br>
            â€œå…­è¶³è½®å¼å˜å½¢æœºå™¨äººâ€é¡¹ç›®ä¸­ï¼Œæœ‰ä¸€é¡¹å‘æ˜ä¸“åˆ©å—ç†ï¼›<br>
            æ­£åœ¨å‚åŠ â€œçµå¿ƒå·§æ‰‹-Xboticsâ€å®ä¹ ï¼›<br>
            2023-2024å­¦å¹´å›½å®¶å¥–å­¦é‡‘ï¼›<br>
            ç¬¬åå…«å±Šâ€œé«˜æ•™æ¯â€å…¨å›½å¤§å­¦ç”Ÿå…ˆè¿›æˆå›¾æŠ€æœ¯ä¸äº§å“ä¿¡æ¯å»ºæ¨¡åˆ›æ–°å¤§èµ›<strong>å›½å®¶çº§äºŒç­‰å¥–</strong>ï¼›<br>
            å…¶ä»–çœçº§ç«èµ›è·å¥–è‹¥å¹²ã€‚
        </p>
        <p class="chinese">
            <strong>æŠ€èƒ½ä¸ç‰¹é•¿ï¼š</strong><br>
            ğŸ”§ ç¡¬ä»¶è®¾è®¡ï¼šSolidworkså»ºæ¨¡ã€PCBç»˜åˆ¶<br>
            ğŸ’» åµŒå…¥å¼å¹³å°ï¼šJetsonã€RK3588ã€STM32<br>
            ğŸ¤– æœºå™¨äººç³»ç»Ÿï¼šROS1<br>
            ğŸ§  æ·±åº¦å­¦ä¹ ï¼šPyTorch<br>
            ğŸ® ä»¿çœŸå¹³å°ï¼šMujocoã€Isaac Sim<br>
            ğŸ¯ å¼ºåŒ–å­¦ä¹ ï¼šSim-to-Realã€RL
        </p>
    </div>

    <!-- <div class="container">
        <h2>Our Task and Vision</h2>
        <p>
            The development of <b>Robots for general-purpose</b> has long been a shared dream of humanity, as their
            realization
            would significantly enhance productivityâ€”by, for instance, performing tasks typically undertaken by nurses
            or cleaning staffâ€”and improve the quality of life through applications such as domestic service robots. A
            general-purpose robot must be capable of executing a wide range of tasks in diverse and open-ended
            environments, posing a formidable challenge in the field of artificial intelligence. The crux of this
            challenge lies in enabling robots to acquire human behavioral capabilities.

            Building upon a strong foundation in the visual understanding of human behavior, we aim to explore a novel
            approach: empowering robots to learn comprehensive, general-purpose behaviors by observing and interpreting
            vast amounts of human activity in video form. Compared to the mainstream
            approach of guiding robotic behavior through large language models, our strategy offers several advantages
            in achieving generalizability:
        <ul>
            <li><b>Autonomous Learning:</b> Human behavior videos capture the full scope of tasks and their various
                possibilities, circumventing the limitations of manually defined tasks.</li><br>
            <li><b>Scalability:</b> The extensive accumulation of videos through the growth of the internet covers
                nearly
                every conceivable human task and operation.</li><br>
            <li><b>Automatic Expansion:</b> With large volumes of new videos uploaded daily, robots can automatically
                extend
                their capabilities to include new tasks and skills.</li>
        </ul>

        By implementing this innovative approach, we pave the way for a more universally applicable and effective
        solution to the challenge of creating general-purpose robots.
        </p> -->

        <!-- <hr width="80%"> -->
        <!-- <br>
        <div class="image_line">
            <img src="recruit/2024/æœºå™¨äººåˆ®èƒ¡å­.gif" width="180px">
            <img src="recruit/2024/æœºå™¨äººå è¡£æœ.gif" width="180px">
            <img src="recruit/2024/æœºå™¨äººå‰Šé»„ç“œ.gif" width="180px">
            <img src="recruit/2024/æœºå™¨äººæ”¶æ‹¾å®¶åŠ¡.gif" width="180px">
        </div>
        <br> -->

        <!-- <hr width="80%"> -->

        <!-- <p class="chinese">
            å®éªŒå®¤ç ”ç©¶æ–¹å‘ä¸ºé€šç”¨æœºå™¨äººï¼ˆå…·èº«æ™ºèƒ½ï¼‰ï¼Œæ˜¯å®ç°é€šç”¨äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ã€‚ä¸è¢«åŠ¨æ¥æ”¶ä¿¡æ¯ä¸åŒï¼Œå…·èº«æ™ºèƒ½å¼ºè°ƒæ™ºèƒ½ä½“ä¸»åŠ¨ä¸ç‰©ç†ç¯å¢ƒè¿›è¡Œäº¤äº’ã€‚äººç±»ä¹Ÿåœ¨æ–‡è‰ºä½œå“é‡Œæç»˜è¿‡å¾ˆå¤šæµªæ¼«çš„æœºå™¨äººæ•…äº‹ï¼Œæ¯”å¦‚ã€Šæœºå™¨ç®¡å®¶ã€‹ä¸­çš„å®‰å¾·é²ã€ã€Šæœºå™¨äººæ€»åŠ¨å‘˜ã€‹ä¸­çš„ç“¦åˆ©å’Œå¤å¨ƒã€ã€Šæ˜Ÿçƒå¤§æˆ˜ã€‹é‡Œçš„R2-D2å’ŒC-3POç­‰ç­‰ã€‚
            å…·èº«æ™ºèƒ½é©±åŠ¨çš„é€šç”¨æœºå™¨äººå°†æ˜¯äººå·¥æ™ºèƒ½çš„ç»ˆæçŠ¶æ€ï¼Œä¹Ÿæ˜¯ç›®å‰å›½é™…å­¦æœ¯å’Œäº§ä¸šå‰æ²¿ã€‚è‹±ä¼Ÿè¾¾CEOé»„ä»å‹‹åœ¨2023 world ITFå¤§ä¼šè¡¨ç¤ºï¼šThe next wave of AI, known as embodied
            AI, refers to intelligent systems that can understand, reason about, and interact with the physical
            worldã€‚å³ï¼Œäººå·¥æ™ºèƒ½çš„ä¸‹ä¸€æ³¢æµªæ½®è¢«ç§°ä¸ºå…·èº«æ™ºèƒ½ï¼Œå®ƒæŒ‡çš„æ˜¯èƒ½å¤Ÿç†è§£ã€æ¨ç†å’Œä¸ç‰©ç†ä¸–ç•Œäº’åŠ¨çš„æ™ºèƒ½ç³»ç»Ÿã€‚æœŸå¾…å¤§å®¶çš„åŠ å…¥å’Œæˆ‘ä»¬ä¸€èµ·æ¨åŠ¨æ¨åŠ¨å…·èº«æ™ºèƒ½çš„å˜é©ã€‚
        </p> -->

    </div>

    <!-- <div class="container">
        <h2>News</h2>
        <p>
            [2024] Six papers were accepted by ECCV 2024.
            <br>
            <br>
            [2024] Four papers were accepted by ICRA 2024.
            <br>
            <br>
            [2024] Five papers were accepted by CVPR 2024.
            <br>
            <br>
            [2022] One paper was accepted by <strong>Nature</strong> (One of two corresponding authors)
            <a href="https://www.nature.com/articles/s41586-022-04507-5">Link</a>.
            <br>
            <br>
            [2022] Ten papers were accepted by CVPR 2022.
            <br>
            <br>
            [2020] One paper was accepted by <strong>Nature Machine Intelligence</strong>
            <a href="https://www.nature.com/articles/s42256-020-0168-3">Link</a>.
            <br>
            <br>
            [2020] The concept of the General-Purpose Intelligent Agent
            (<a href="https://www.sciencedirect.com/science/article/pii/S2095809919309075">GIA</a>)
            has been published in <strong>Engineering</strong>.
            <br>
            <br>
            [2020] Seven papers were accepted by <strong>CVPR</strong> 2020
            <a href="/publications.html">Link</a>.
            <br>
            <br>
            [2020] Prof. Lu Cewu will serve as an <strong>Area Chair</strong> for CVPR 2020.
            <br>
            <br>
            [2020] <b><a href="http://hake-mvig.cn">
                    <span style="color: red" size="6px">H</span><span style="color: blue" size="6px">A</span><span
                        style="color: red" size="6px">KE</span></a></b>: Human Activity Knowledge Engine begins trial
            operation!
            <a href="http://hake-mvig.cn">Link</a>.
            <br>
            <br>
            [2019] VALSE 2019: Knowledge Driven Human Activity Understanding
            <a href="/research/VALSE2019.html">Talk</a>.
            <br>
            <br>
            [2018] PRCV 2018: Activity Understanding meets 3D Representation
            <a href="/research/PRCV2019.html">Talk</a>.
            <br>
            <br>
            [2017] AlphaPose is released, a pose estimation system based on our RMPE[ICCV'17], relatively outperforms
            Mask RCNN by 8.2% on COCO dataset pose task.
            <a href="/research/alphapose.html">AlphaPose</a>.
            <br>
            <br>
             [Year] We propose a new task of Action Adverb recognition.
            <a href="/research/adha/adha.html">ADHA</a>.
            <br> -->
    <!-- [2017] Prof. Lu Cewu is selected as MIT TR35 - "MIT Technology Review, 35 Innovators Under 35 (China)"
            <a href="http://www.mittrchina.com/news/1623">MIT Technology Review</a>. -->
    </p>
    </div> 

    <div class="container" style="text-align: center;">
        <h2>ğŸŠContact & Social Media</h2>
        <div class="social-links">
            <a href="https://github.com/daizhou-xd" target="_blank">
                <img src="https://img.shields.io/badge/-GitHub-181717?style=flat-square&logo=github&logoColor=ffffff" alt="GitHub">
            </a>
            <a href="https://space.bilibili.com/489658578" target="_blank">
                <img src="https://img.shields.io/badge/-Bilibili-00A1D6?style=flat-square&logo=bilibili&logoColor=ffffff" alt="Bilibili">
            </a>
            <a href="https://blog.csdn.net/tornado____?type=blog" target="_blank">
                <img src="https://img.shields.io/badge/-CSDN-CF000E?style=flat-square&logo=CSDN&logoColor=ffffff" alt="CSDN">
            </a>
            <a href="https://www.zhihu.com/people/pi-li-xiao-zi-74-92" target="_blank">
                <img src="https://img.shields.io/badge/-çŸ¥ä¹-0084FF?style=flat-square&logo=zhihu&logoColor=ffffff" alt="çŸ¥ä¹">
            </a>
        </div>
    </div>

</body>

</html>